{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43be957-2157-4061-b367-61bc3c025f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354eaf3a-311b-4573-ac5c-4369ffae18ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. Load the Dataset\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Customer_Churn.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce1a9e9-624c-466b-8a89-9d1b5673514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paras singhal\\AppData\\Local\\Temp\\ipykernel_25340\\1424809432.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)  # Fill missing values with median\n"
     ]
    }
   ],
   "source": [
    "#3. Data Cleaning and Preparation\n",
    "\n",
    "#3.1. Handle Missing Values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values for TotalCharges\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Convert to numeric, force errors to NaN\n",
    "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)  # Fill missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd66b17c-e65e-4670-9d2d-dce9b11c2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2. Convert Target Variable\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e89c72-5e78-4e95-b8df-697d5a085c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Feature Engineering and Preprocessing\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['Churn', 'customerID'])  # Drop target and any non-predictive columns\n",
    "y = df['Churn']\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', \n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "                        'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84848fb-2ebe-432e-9210-5b04099b5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Preprocessing Pipeline\n",
    "#4.1 Define Categorical and Numerical Features\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', \n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "                        'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cc653d-f53a-4247-bdb8-4e7abbf7558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Create Preprocessing Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values by replacing with median\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values by replacing with the most frequent value\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Convert categorical features to one-hot encoded format\n",
    "])\n",
    "\n",
    "# Combine pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Apply numerical pipeline to numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Apply categorical pipeline to categorical features\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8acfbb-6243-4dcc-ad9a-81d7e9e5c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Preprocessing Pipeline\n",
    "#Fit and Transform Data\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Churn', 'customerID'])  # Drop target and non-predictive columns\n",
    "y = df['Churn']\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5a29c8-5a6f-4cd4-b46f-b3707b9b1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b484c5-08b0-4f07-a22e-ddaff6c7d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7963094393186657\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1036\n",
      "           1       0.66      0.47      0.55       373\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.74      0.69      0.71      1409\n",
      "weighted avg       0.78      0.80      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fea4b2e-4872-49fb-bc21-88f16916a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Prepare Data for Modeling\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Customer_Churn.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Churn', 'customerID'])  # Drop the target column and non-predictive column\n",
    "y = df['Churn']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67a3831-99c8-4c80-9a9e-69835ad61800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8218594748048261\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.90      0.88      1036\n",
      "         Yes       0.69      0.60      0.64       373\n",
      "\n",
      "    accuracy                           0.82      1409\n",
      "   macro avg       0.77      0.75      0.76      1409\n",
      "weighted avg       0.82      0.82      0.82      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Customer_Churn.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Churn', 'customerID'])  # Drop the target column and non-predictive column\n",
    "y = df['Churn']  # Target variable\n",
    "\n",
    "# Check and convert data types for numerical features\n",
    "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "for col in numerical_features:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')  # Convert to numeric, forcing errors to NaN\n",
    "\n",
    "# Define categorical features\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', \n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "                        'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())  # Feature scaling\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Convert categorical data to numerical\n",
    "])\n",
    "\n",
    "# Combine pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Apply numerical pipeline to numerical features\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Apply categorical pipeline to categorical features\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = LogisticRegression(max_iter=1000)  # Increase max_iter if necessary for convergence\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd44fdb2-388b-40c7-82bf-b20969b39842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Score: 0.8017399499764382\n"
     ]
    }
   ],
   "source": [
    "#6. Hyperparameter Tuning\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression and GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Optimization algorithms\n",
    "    'penalty': ['l1', 'l2']  # Regularization types\n",
    "}\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa1a0b1-298e-43aa-8059-94e2022da235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Score: 0.8017399499764382\n",
      "Test Accuracy Score of Loaded Model: 0.8225691980127751\n",
      "Test Classification Report of Loaded Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.91      0.88      1036\n",
      "         Yes       0.70      0.58      0.64       373\n",
      "\n",
      "    accuracy                           0.82      1409\n",
      "   macro avg       0.78      0.75      0.76      1409\n",
      "weighted avg       0.82      0.82      0.82      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Optimization algorithms\n",
    "    'penalty': ['l1', 'l2']  # Regularization types\n",
    "}\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Check if best_estimator_ exists and print the best parameters\n",
    "if hasattr(grid_search, 'best_estimator_'):\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "    # Save the best model to a file\n",
    "    joblib.dump(grid_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "    # Load the model back to verify\n",
    "    loaded_model = joblib.load('best_model.pkl')\n",
    "\n",
    "    # Optional: Verify that the loaded model works correctly\n",
    "    # Evaluate the loaded model on the test set\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "    print(\"Test Accuracy Score of Loaded Model:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Test Classification Report of Loaded Model:\\n\", classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"The grid search did not produce a best estimator.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadc71e1-9e62-4886-8a95-243fa3d511c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create label encoders\n",
    "le_gender = LabelEncoder()\n",
    "le_gender.fit(['Male', 'Female'])\n",
    "\n",
    "le_partner = LabelEncoder()\n",
    "le_partner.fit(['Yes', 'No'])\n",
    "\n",
    "le_dependents = LabelEncoder()\n",
    "le_dependents.fit(['Yes', 'No'])\n",
    "\n",
    "le_internet_service = LabelEncoder()\n",
    "le_internet_service.fit(['DSL', 'Fiber optic', 'No'])\n",
    "\n",
    "# Save the label encoders as a dictionary\n",
    "label_encoders = {\n",
    "    'gender': le_gender,\n",
    "    'Partner': le_partner,\n",
    "    'Dependents': le_dependents,\n",
    "    'InternetService': le_internet_service\n",
    "}\n",
    "\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52f5cd3-ecbb-4f45-8bd8-587657d503c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': LabelEncoder(), 'Partner': LabelEncoder(), 'Dependents': LabelEncoder(), 'InternetService': LabelEncoder()}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "label_encoders = joblib.load('label_encoders.pkl')\n",
    "print(label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b4bc8-4130-44bb-9d45-e280fd146b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
